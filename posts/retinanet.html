<!doctype html>
<html lang="en">

<head>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The Art of Machine Learning</title>
  <meta name="description" content="Machine Learning, Deep Learning, Jenny Yu, denver ">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Bayesian methods">
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://yinniyu.github.io/posts/retinanet.html">
  <meta property="og:site_name" content="The Art of Machine Learning">
  <meta property="og:image" content="images/retinanet/true positive.png">

 
  <link rel="apple-touch-icon" href="/assets/apple-touch-icon.png">
  <link href="http://chalk.nielsenramon.com/feed.xml" type="application/rss+xml" rel="alternate" title="Chalk Last 10 blog posts" />

    <link rel="stylesheet" href="/assets/light.css">

  
</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav appear">
  <a href="/" class="header-logo" title="The Art of Machine Learning">The Art of Machine Learning</a>
  <ul class="header-links">

    <li>
        <a href="https://yinniyu.github.io/about">About Me
        </a>
      </li>
    
    <li>
        <a href="https://yinniyu.github.io/toolbox">My Toolbox</a>
      </li>
    
     <li>
        <a href="https://github.com/yinniyu" rel="noreferrer noopener" target="_blank" title="GitHub">
          <span class="icon icon-github"></span>
        </a>
      </li>
    
    
      <li>
        <a href="https://linkedin.com/in/jenny-yu-b495243" rel="noreferrer noopener" target="_blank" title="LinkedIn">
          <span class="icon icon-linkedin"></span>
        </a>
      </li>   
  </ul>
</nav>

        
        <article class="article appear">
          <header class="article-header">
            <h1>RetinaNet lung opacity detection (with meta data)</h1>
            <figure>
              <p align='center'><img src='images/retinanet/true positive.png' alt="dicom_bbox" ></p>
            </figure>
            <p>The Radiological Society of North America (RSNA) recently hosted a Kaggle competition, where Kagglers are asked to 
              build a model to screen for marker of pneumonia by detecting lung opacity on chest radiographs. The standard practice for 
             diagnosis of pneumonia is time consuming - requiring review of radiographs by trained professional, vital sign, and clinical 
            history of the individual patient. The quality of the chest radiograph (CXR) also makes accurate diagnosis a challenging task,
           because the opaque features can be caused by pulmonary edema, bleeding, lung cancer, or fluid in the 
              pleural space (pleural effusion)[1]. To quote the RSNA:</p>
            <blockquote class="w3-panel w3-leftbar w3-light-grey">
                <i>"They see the potential for ML to automate initial detection 
       (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review."</i>
            </blockquote> 

            <p>I tried out the <a href='https://github.com/fizyr/keras-retinanet'><u> RetinaNet object detector</u> </a>
              (implemented in Keras by Fizyr) on the image dataset, but ran out of time to submit before the deadline. For this 
              post, I will focus mostly on model performance and tradeoff associated with using meta data from the dicom image 
              files. But before going into that, I will explain why I chose RetinaNet.
            </p>
            
            <div class="article-list-footer">
              <span class="article-list-date">
                Nov 3th, 2018
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
              15 minute read
              </span>
              
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                <span class="article-list-divider">Keras, RetinaNet, Object Detection</span>
              </div>
            </div>
          </header>

          <div class="article-content">
  

<h2 id="background">RetinaNet</h2>

<p>RetinaNet is a single-stage object detector proposed in the paper 
  <a href='https://arxiv.org/abs/1708.02002'><b>Focal Loss for Dense Object Detection</b></a> 
  by Tsung-Yi Lin, Priya Goyal, et al. In addition to having faster processing speed,
  it offers higher accuracy in small object detection compared to YOLO and even SSD, thanks to Feature Pyramid Network (FPN) (Fig. 1).
  
  
  
  
  

       <figure>
      <center><img src="images/retinanet/retinanet_schema.png" alt="retina architecture" ></center>
   <figcaption>Fig.1. RetinaNet(Source:https://arxiv.org/pdf/1708.02002.pdf). 
   </figcaption>
   </figure>      
  
  
  <figure>
      <center><img src="images/retinanet/object_detect_comp.png" alt="COCO data comparison" ></center>
   <figcaption>Fig.2. <a href='https://medium.com/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359'>Comparison </i>of performance on COCO dataset. 
   </figcaption>
   </figure>  

<h2 id="pymc3">PyMC3</h2>

<p>As stated in the PyMC3 tutorial, NUTS is best used for continuous parameter sampling, and Metropolis for categroical parameter. 
            In the figure below, I share an example of running a logistic model consists of both continuous and categorical inputs to 
            produce a binary outcome value. I find that the easiest way to incorporate mixed data type in PyMC3 is to define your own 
            function (instead of using the default pm.glm.GLM() function).</p>
     <figure>
      <center><img src="images/bayesian/pymc3_lr.png" alt="pymc3_lr" ></center>
   <figcaption>Fig.2. Example of training a probilistic programming model using PyMC3 sampling, and generating the sampling results (trace plot).
   </figcaption>
   </figure>
   
  
<p>In defining the distribution of the categorical variables (there were 7), either Bernoulli or Binomial distributions can be used.
  With <code class="highlighter-rouge">pm.Binomial()</code>, user must enter number of trials (e.g., n=10) since Binomial function 
            is concerned with number of trials. Another useful feature of PyMC3 is that user can define multiple steps to assign 
            different sampling method to the desired variable(s). It's also helpful to use the <code class="highlighter-rouge">
  share()</code> function from PyMC3 to later share the out-of-sample test data in order to run inference on the trained model(see code below).</p>
            
 <figure class="highlight"><pre><code class="language-Python" data-lang="Python">
############### after model is trained #############

#switch variable values to predictors_out_of_sample data, then run model by sampling 200 times for each data point
predictors_shared.set_value(predictors_out_of_sample)
ppc = pm.sample_ppc(trace_bern, model=model, samples=200)

# To generate a final prediction value, use beta function to characterize the prediction distribution.
# beta distribution is frequently used in Bayesian statistics, empirical Bayes methods and classical statistics to 
#capture overdispersion in binomial type distributed data. when n(number of samples in code above) =1, then 
#it's bernoulli distribution
β = st.beta((ppc['outcomes'] == 1).sum(axis=0), (ppc['outcomes'] == 0).sum(axis=0))
pred_eval=pd.DataFrame({'ppc_pred':β.mean(), 'actual_value':y_test.values})

</code></pre></figure>         
  

  <h3> Conclusion </h3>
  <p> With sufficient samplings, Bayesian modeling outperformed regular logistic regression fitting by a 
    slight margin in F1 score. Given the computational cost, it would be more efficient to apply probabilistic programming 
    to complex model with higher dimensions than the dataset used for the code presented here. Currently there's great interest
    in training models with Bayesian Neural Network that is capable of generating prediction/posterior distributions, and 
    yielding higher accuracy[3]. However, within PyMC3 there's been some issues with saving the model and the 
    trace file - when user reloads it to run on 
    new dataset it <a href='https://discourse.pymc.io/t/out-of-sample-predictions-from-a-pickled-model/956'> doesn't accept </a>
    the new data (i.e., failing due to broadcasting different sample length). Hopefully PyMC3 and other packages like Edward 
    would roll out improvements for more robust backend support.
            </p>
    
   
  
  <h3> REFERENCES </h3>
  <p>[1]RSNA Pneumonia Detection Challenge, https://www.kaggle.com/c/rsna-pneumonia-detection-challenge</p>
  <p>[2]Hoffman, M.D., Gelman, A. (2011). <b>The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian 
    Monte Carlo </b>.</p>
  <p>[3]Mullachery, V., Khera,A., Husain, A. (2018). <i>Bayesian Neural Networks.</p>

  
    
    
    
            <div id="disqus_thread" class="article-comments"></div>
            <script src="https://chalk-1.disqus.com/embed.js" async defer></script>
            <noscript>Please enable JavaScript to view the comments.</noscript>
          
        </article>
        <footer class="footer appear">
          
   
    Chalk is a high quality, completely customizable, performant and 100% free
    blog template for Jekyll built by
    <a href="/about" title="About me">Nielsen Ramon</a>. Download it <a href="https://github.com/nielsenramon/chalk" rel="noreferrer noopener" target="_blank" title="Download Chalk">here</a>.
  </p>
</footer>

      </div>
    </div>
  </main>
  
  <script>
    window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
    ga('create','UA-28631876-6','auto');ga('send','pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async></script>


<script src="/assets/vendor.js"></script>



  <script src="/assets/webfonts.js"></script>




  <script src="/assets/scrollappear.js"></script>



<script src="/assets/application.js"></script>


</body>
</html>
